from fastapi import FastAPI
from langchain_core.prompts import ChatPromptTemplate
from langserve import add_routes
import uvicorn
import os
from langchain_community.llms import Ollama
from dotenv import load_dotenv

load_dotenv()


os.environ["LANGCHAIN_API_KEY"] = os.getenv("LANGCHAIN_API_KEY")
os.environ["LANGCHAIN_TRACING_V2"] = "true"

app = FastAPI(
    title = "langchain-server",
    version = "1.0",
    description = "a simple langchain server"
)

# define the model 
llm = Ollama(model="llama3.2")

prompt = ChatPromptTemplate.from_messages([
    ("human", "Write me an 100 wordessay about {topic} for a five year old kid.")
])

add_routes(
    app, 
    prompt | llm,
    path = "/essay"
)

if __name__ == "__main__":
    uvicorn.run(app, host="localhost", port=8000)